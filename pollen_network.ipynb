{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pollen-Detection-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a class for fully convolutional neural networks.\n",
    "    \n",
    "    It is a subclass of the Module class from torch.nn.\n",
    "    See the torch.nn documentation for more information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor for FCNN class. The internal states of the network are initialized. \n",
    "        \"\"\"\n",
    "        \n",
    "        super(FCNN, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=30, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=30, out_channels=60, kernel_size=3, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=60, out_channels=60, kernel_size=3, stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=60, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=120, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=120, out_channels=1, kernel_size=1, stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Defines the computation performed at every call.\n",
    "        \n",
    "        Parameters:\n",
    "            data (torch.Tensor): The input that is evaluated by the network. \n",
    "                The network expects the input to be of 4 dimensions.\n",
    "            \n",
    "        Returns:\n",
    "            x (torch.Tensor): The output of the network after evaluating it on the given input.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.relu(self.conv0(data))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2_drop(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_drop(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = torch.sigmoid(self.conv6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, testloader):\n",
    "    \"\"\"\n",
    "    Calculates the mean validation loss, the F1-Score and the accuracy of the given network on the testloader data.\n",
    "    \n",
    "    Parameters:\n",
    "        network (nn.Module): The network to validate. \n",
    "        testloader (torch.utils.data.DataLoader): Contains the data which is used to validate the network. \n",
    "        \n",
    "    Returns:\n",
    "        validation_loss (float): The mean loss per image with regards to a fixed criterion.\n",
    "        F1_Score (float): The harmonic mean of the precision and the recall of the given network\n",
    "            on the given validation data.\n",
    "        correct / total (float): The percentage of correctly classified samples of the \n",
    "            total number of validation samples.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    true_positive = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "\n",
    "    # We do not need any gradiants here, since we do not train the network.\n",
    "    # We are only interested in the predictions of the network on the testdata. \n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        for i, sample in enumerate(testloader):\n",
    "#         for i, (inputs, labels) in enumerate(testloader):\n",
    "            \n",
    "            inputs = sample[0].to(device)\n",
    "            labels = sample[1].to(device)\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)).view(-1)\n",
    "            loss = criterion(outputs,labels)\n",
    "            validation_loss += loss.item()\n",
    "            predicted = (outputs >= threshold) # Predicted is a tensor of booleans \n",
    "            total += labels.size(0)\n",
    "            predicted = predicted.view(predicted.size(0)) \n",
    "            b_labels = labels != 0\n",
    "            correct += (predicted == b_labels).sum().item()\n",
    "            true_positive += (predicted & b_labels).sum().item()\n",
    "            false_negative += (np.logical_not(np.array(torch.Tensor.cpu(predicted))) & np.array(torch.Tensor.cpu(b_labels))).sum()\n",
    "            \n",
    "        f_validation_loss = validation_loss / total \n",
    "        true_negative = correct - true_positive\n",
    "        false_positive = total - correct - false_negative\n",
    "        \n",
    "        try: \n",
    "            recall = true_positive / (true_positive + false_negative)\n",
    "        except ZeroDivisionError:\n",
    "            recall = 0\n",
    "        try:\n",
    "            precision = true_positive / (true_positive + false_positive)\n",
    "        except ZeroDivisionError:\n",
    "            precision = 0\n",
    "        try:\n",
    "            F1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        except ZeroDivisionError:\n",
    "            F1_score = 0\n",
    "            \n",
    "    \n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "    print('F1 Score of the network on the test images: %f' % F1_score)\n",
    "    return f_validation_loss, F1_score, (correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, trainloader, validloader, ep, criterion, optimizer, print_interval):\n",
    "    \"\"\"\n",
    "    Train a neural network.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        network (nn.Module): The network which should be trained.\n",
    "        trainloader (torch.utils.data.DataLoader): Contains the data to be used to train the network.\n",
    "        ep (int): The number of epochs the network will be trained for.\n",
    "        criterion (): The loss function used for training (should be the same for validation).\n",
    "        optimizer (): The specification how the weights are optimized.\n",
    "        print_interval (int): The number of batches after which the function prints the loss for one batch.\n",
    "    \n",
    "    Returns:\n",
    "        train_losses ([float]): The mean of the loss for one train sample after every epoch. \n",
    "        validation_losses ([float]): The mean of the loss for one validation sample after every epoch.\n",
    "        F1 ([float]): The F1-Score of the validation data after every epoch.\n",
    "        accuracy ([float]): The accuracy of the network on the validation data after every epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = [] # Mean of loss/image in every epoch of training \n",
    "    validation_losses = []\n",
    "    F1 = []\n",
    "    accuracy = []\n",
    "    print('Performance of the untrained network:')\n",
    "    validate(network, validloader)\n",
    "    \n",
    "    for epoch in range(ep):\n",
    "\n",
    "        loss_stats = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, sample in enumerate(trainloader):\n",
    "#         for i, (inputs, labels) in enumerate(trainloader):\n",
    "            \n",
    "            inputs = sample[0].to(device)\n",
    "            labels = sample[1].to(device)\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(labels.shape)\n",
    "            \n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)).view(-1)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() #propagate the error back through the network\n",
    "            optimizer.step() #adjust the weights of the network depending on the propagated error\n",
    "    \n",
    "            #that's it.\n",
    "            total += labels.shape[0]\n",
    "            \n",
    "            #Some statistics:\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            loss_stats += loss.item()\n",
    "            \n",
    "            if i % print_interval == print_interval - 1:    # print every x mini-batches (loss for one batch)\n",
    "                print('[Epoch: %d, Batch: %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / print_interval))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        losses.append(loss_stats / total) \n",
    "        #Test the network using the validation set after every epoch of training.\n",
    "        val_loss_curr, F1_curr, accuracy_curr = validate(network, validloader)\n",
    "        validation_losses.append(val_loss_curr)\n",
    "        F1.append(F1_curr)\n",
    "        accuracy.append(accuracy_curr)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return losses, validation_losses, F1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelStrengthDataset(DatasetFolder):\n",
    "    \"\"\"A generic data loader where the samples are arranged in this way: ::\n",
    "        root/class_x/smpl1\n",
    "        root/class_x/smpl2\n",
    "        \n",
    "        root/class_y/smpl3\n",
    "        root/class_y/smpl4\n",
    "        p\n",
    "        with a single dictionary containing all samples as keys and their labelstrength as values\n",
    "        \n",
    "    Args:\n",
    "        root (String):    path to root\n",
    "        ls_file (String): path to pickle file containing the dictionary\n",
    "    \n",
    "    Attributes:\n",
    "        root: path to root\n",
    "        ls: dictionary with image names as keys and labelstrengths as values\n",
    "        transform: transformations applied on samples\n",
    "        samples: List of tuples containing a path to an image and its label strength\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root, ls_file, transform=None):\n",
    "        with open(ls_file, 'rb') as pklfile:\n",
    "            self.ls = pickle.load(pklfile)\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.samples = self.make_dataset()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ls)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.samples[index][0]\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        np_image = np.array(image)\n",
    "        t_image = torch.Tensor(np_image)\n",
    "        labelstrength = self.samples[index][1]\n",
    "        sample = (t_image, labelstrength)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def make_dataset(self):\n",
    "        \"\"\"Creates List of Tulpes containing path to img and its labelstrength\"\"\"\n",
    "        print(\"Create Dataset..\")\n",
    "        instances = []\n",
    "        for root, folders, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file.lower().endswith('.png'):\n",
    "                    img_path = os.path.join(root,file)\n",
    "                    label = self.ls[file]\n",
    "#                     t_label = torch.tensor(label)\n",
    "                    item = img_path, label\n",
    "                    instances.append(item)\n",
    "        print(\"Dataset created.\")\n",
    "        return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tkf/Desktop/dev/pollen-detection'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(cwd, 'Datasets/PollenData/')\n",
    "pickle_dir = os.path.join(root, 'labelstrength.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset..\n",
      "Dataset created.\n"
     ]
    }
   ],
   "source": [
    "dataset = LabelStrengthDataset(root, pickle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train- and Testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ratio = .8\n",
    "shuffle_dataset = True\n",
    "seed = np.random.randint\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(train_ratio * dataset_size))\n",
    "\n",
    "if shuffle_dataset:\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, valid_indices = indices[:split], indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can train our network with given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup wether gpu or cpu should be used for computations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a new instance of the FCNN class. This will be our network.      \n",
    "pollen_network = FCNN().to(device)\n",
    "    \n",
    "# Choose optimizer, criterion, number of epochs and threshold for the network to accept or dismiss a computated input\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(pollen_network.parameters(), lr=0.001, momentum=0.9)\n",
    "ep = 10\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs  <class 'torch.Tensor'> tensor([[[ 25.,  26.,  30.,  ...,  44.,  48.,  49.],\n",
      "         [ 26.,  27.,  30.,  ...,  46.,  48.,  49.],\n",
      "         [ 24.,  26.,  29.,  ...,  44.,  49.,  54.],\n",
      "         ...,\n",
      "         [108., 109., 108.,  ...,  28.,  28.,  28.],\n",
      "         [110., 112., 108.,  ...,  26.,  28.,  30.],\n",
      "         [110., 114., 108.,  ...,  30.,  28.,  30.]],\n",
      "\n",
      "        [[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.]],\n",
      "\n",
      "        [[242., 255., 255.,  ..., 246., 242., 252.],\n",
      "         [247., 242., 245.,  ..., 255., 253., 251.],\n",
      "         [247., 250., 239.,  ..., 250., 255., 255.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 251., 238., 250.],\n",
      "         [255., 246., 255.,  ..., 239., 251., 255.],\n",
      "         [249., 255., 255.,  ..., 255., 255., 255.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[255., 254., 252.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 254.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.]],\n",
      "\n",
      "        [[124., 106.,  99.,  ...,  82.,  76.,  70.],\n",
      "         [122., 106.,  96.,  ...,  82.,  76.,  76.],\n",
      "         [124., 108., 100.,  ...,  84.,  81.,  81.],\n",
      "         ...,\n",
      "         [183., 194., 195.,  ..., 255., 255., 255.],\n",
      "         [184., 195., 195.,  ..., 255., 255., 255.],\n",
      "         [190., 196., 196.,  ..., 255., 255., 255.]],\n",
      "\n",
      "        [[ 61.,  61.,  60.,  ...,  54.,  55.,  56.],\n",
      "         [ 61.,  62.,  61.,  ...,  54.,  55.,  55.],\n",
      "         [ 60.,  61.,  61.,  ...,  54.,  55.,  55.],\n",
      "         ...,\n",
      "         [ 45.,  44.,  45.,  ...,  84.,  82.,  79.],\n",
      "         [ 45.,  45.,  45.,  ...,  84.,  82.,  80.],\n",
      "         [ 45.,  45.,  45.,  ...,  83.,  82.,  80.]]])\n",
      "Labels <class 'torch.Tensor'> tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9112], dtype=torch.float64)\n",
      "Outputs <class 'torch.Tensor'> tensor([0.5306, 0.0939, 0.8251, 0.6305, 0.1341, 0.5444, 0.5437, 0.4785, 0.5023,\n",
      "        0.5957, 0.5214, 0.4858, 0.5069, 0.4535, 0.4622, 0.4429, 0.4829, 0.1949,\n",
      "        0.7552, 0.4708])\n",
      "Loss <class 'torch.Tensor'> tensor(0.2615, dtype=torch.float64)\n",
      "Validation_loss <class 'float'> 2831.428361716308\n",
      "Predicted <class 'torch.Tensor'> tensor([False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n",
      "Total <class 'int'> 329940\n",
      "Correct <class 'int'> 282954\n",
      "True_positive <class 'int'> 70\n",
      "False_negative <class 'numpy.int64'> 32941\n",
      "F_Validation_loss <class 'float'> 0.008581646243911946\n",
      "True_negative <class 'int'> 282884\n",
      "False_positive <class 'numpy.int64'> 14045\n",
      "Accuracy of the network on the test images: 85 %\n",
      "F1 Score of the network on the test images: 0.002971\n"
     ]
    }
   ],
   "source": [
    "val_loss_curr, F1_curr, accuracy_curr = validate(pollen_network, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the untrained network:\n",
      "Accuracy of the network on the test images: 85 %\n",
      "F1 Score of the network on the test images: 0.003825\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected dtype Double but got dtype Float (validate_dtype at /pytorch/aten/src/ATen/native/TensorIterator.cpp:143)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f548dbbe536 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types() + 0xce3 (0x7f547ff04483 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build() + 0x44 (0x7f547ff06e64 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::native::mse_loss_backward_out(at::Tensor&, at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x193 (0x7f547fd54e93 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x10b70b7 (0x7f54801810b7 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x172 (0x7f547fd5d5d2 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: <unknown function> + 0x109da6f (0x7f5480167a6f in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10c2f76 (0x7f548018cf76 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0x2a9dfeb (0x7f5481b67feb in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: <unknown function> + 0x10c2f76 (0x7f548018cf76 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: torch::autograd::generated::MseLossBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1f7 (0x7f548196fa87 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x2d88f05 (0x7f5481e52f05 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f5481e50203 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f5481e50fe2 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f5481e49659 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f548e4d3538 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0xee0f (0x7f548eea5e0f in /home/tkf/.local/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so)\nframe #17: <unknown function> + 0x9609 (0x7f54ccc0e609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #18: clone + 0x43 (0x7f54ccd4a103 in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-603613fe3b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpollen_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-99c50a1e835c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, trainloader, validloader, ep, criterion, optimizer, print_interval)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#propagate the error back through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#adjust the weights of the network depending on the propagated error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected dtype Double but got dtype Float (validate_dtype at /pytorch/aten/src/ATen/native/TensorIterator.cpp:143)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f548dbbe536 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types() + 0xce3 (0x7f547ff04483 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build() + 0x44 (0x7f547ff06e64 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::native::mse_loss_backward_out(at::Tensor&, at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x193 (0x7f547fd54e93 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x10b70b7 (0x7f54801810b7 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x172 (0x7f547fd5d5d2 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: <unknown function> + 0x109da6f (0x7f5480167a6f in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10c2f76 (0x7f548018cf76 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0x2a9dfeb (0x7f5481b67feb in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: <unknown function> + 0x10c2f76 (0x7f548018cf76 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: torch::autograd::generated::MseLossBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1f7 (0x7f548196fa87 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x2d88f05 (0x7f5481e52f05 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f5481e50203 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f5481e50fe2 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f5481e49659 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f548e4d3538 in /home/tkf/.local/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0xee0f (0x7f548eea5e0f in /home/tkf/.local/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so)\nframe #17: <unknown function> + 0x9609 (0x7f54ccc0e609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #18: clone + 0x43 (0x7f54ccd4a103 in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, F1_scores, accuracies = train(pollen_network, train_loader, valid_loader, ep, criterion, optimizer, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the networks parameters to have the possibility to reload them later:\n",
    "cur_dir = os.getcwd()\n",
    "save_path = cur_dir + '/pollennet.pt'\n",
    "torch.save(pollen_network.state_dict(), save_path)\n",
    "\n",
    "# save the corresponding losses, F1-Scores and Accuracies using pickle:\n",
    "\n",
    "with open('train_losses_gpu.obj', 'wb') as train_losses_file:\n",
    "    pickle.dump(train_losses, train_losses_file)\n",
    "\n",
    "with open('val_losses_gpu.obj', 'wb') as val_losses_file:\n",
    "    pickle.dump(val_losses, val_losses_file)\n",
    "    \n",
    "with open('F1_gpu.obj', 'wb') as F1_file:\n",
    "    pickle.dump(F1_scores, F1_file)\n",
    "    \n",
    "with open('accuracies_gpu.obj', 'wb') as accuracies_file:\n",
    "    pickle.dump(accuracies, accuracies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the untrained network:\n",
      "Accuracy of the network on the test images: 97 %\n",
      "F1 Score of the network on the test images: 0.879973\n",
      "[Epoch: 1, Batch:    32] loss: 0.018\n",
      "[Epoch: 1, Batch:    64] loss: 0.017\n",
      "[Epoch: 1, Batch:    96] loss: 0.013\n",
      "[Epoch: 1, Batch:   128] loss: 0.017\n",
      "[Epoch: 1, Batch:   160] loss: 0.017\n",
      "[Epoch: 1, Batch:   192] loss: 0.016\n",
      "[Epoch: 1, Batch:   224] loss: 0.011\n",
      "[Epoch: 1, Batch:   256] loss: 0.015\n",
      "[Epoch: 1, Batch:   288] loss: 0.011\n",
      "[Epoch: 1, Batch:   320] loss: 0.011\n",
      "[Epoch: 1, Batch:   352] loss: 0.013\n",
      "[Epoch: 1, Batch:   384] loss: 0.018\n",
      "[Epoch: 1, Batch:   416] loss: 0.019\n",
      "[Epoch: 1, Batch:   448] loss: 0.017\n",
      "[Epoch: 1, Batch:   480] loss: 0.019\n",
      "[Epoch: 1, Batch:   512] loss: 0.014\n",
      "[Epoch: 1, Batch:   544] loss: 0.017\n",
      "[Epoch: 1, Batch:   576] loss: 0.015\n",
      "[Epoch: 1, Batch:   608] loss: 0.016\n",
      "[Epoch: 1, Batch:   640] loss: 0.020\n",
      "[Epoch: 1, Batch:   672] loss: 0.012\n",
      "[Epoch: 1, Batch:   704] loss: 0.014\n",
      "[Epoch: 1, Batch:   736] loss: 0.020\n",
      "[Epoch: 1, Batch:   768] loss: 0.021\n",
      "[Epoch: 1, Batch:   800] loss: 0.016\n",
      "[Epoch: 1, Batch:   832] loss: 0.019\n",
      "[Epoch: 1, Batch:   864] loss: 0.019\n",
      "[Epoch: 1, Batch:   896] loss: 0.017\n",
      "[Epoch: 1, Batch:   928] loss: 0.011\n",
      "[Epoch: 1, Batch:   960] loss: 0.013\n",
      "[Epoch: 1, Batch:   992] loss: 0.015\n",
      "[Epoch: 1, Batch:  1024] loss: 0.019\n",
      "[Epoch: 1, Batch:  1056] loss: 0.014\n",
      "[Epoch: 1, Batch:  1088] loss: 0.014\n",
      "[Epoch: 1, Batch:  1120] loss: 0.009\n",
      "[Epoch: 1, Batch:  1152] loss: 0.017\n",
      "[Epoch: 1, Batch:  1184] loss: 0.013\n",
      "[Epoch: 1, Batch:  1216] loss: 0.014\n",
      "[Epoch: 1, Batch:  1248] loss: 0.013\n",
      "[Epoch: 1, Batch:  1280] loss: 0.025\n",
      "[Epoch: 1, Batch:  1312] loss: 0.014\n",
      "[Epoch: 1, Batch:  1344] loss: 0.017\n",
      "[Epoch: 1, Batch:  1376] loss: 0.014\n",
      "[Epoch: 1, Batch:  1408] loss: 0.014\n",
      "[Epoch: 1, Batch:  1440] loss: 0.011\n",
      "[Epoch: 1, Batch:  1472] loss: 0.018\n",
      "[Epoch: 1, Batch:  1504] loss: 0.013\n",
      "[Epoch: 1, Batch:  1536] loss: 0.018\n",
      "[Epoch: 1, Batch:  1568] loss: 0.019\n",
      "[Epoch: 1, Batch:  1600] loss: 0.014\n",
      "[Epoch: 1, Batch:  1632] loss: 0.017\n",
      "[Epoch: 1, Batch:  1664] loss: 0.017\n",
      "[Epoch: 1, Batch:  1696] loss: 0.018\n",
      "[Epoch: 1, Batch:  1728] loss: 0.014\n",
      "[Epoch: 1, Batch:  1760] loss: 0.013\n",
      "[Epoch: 1, Batch:  1792] loss: 0.023\n",
      "[Epoch: 1, Batch:  1824] loss: 0.021\n",
      "[Epoch: 1, Batch:  1856] loss: 0.021\n",
      "[Epoch: 1, Batch:  1888] loss: 0.017\n",
      "[Epoch: 1, Batch:  1920] loss: 0.023\n",
      "[Epoch: 1, Batch:  1952] loss: 0.014\n",
      "[Epoch: 1, Batch:  1984] loss: 0.016\n",
      "[Epoch: 1, Batch:  2016] loss: 0.018\n",
      "[Epoch: 1, Batch:  2048] loss: 0.014\n",
      "[Epoch: 1, Batch:  2080] loss: 0.015\n",
      "[Epoch: 1, Batch:  2112] loss: 0.017\n",
      "[Epoch: 1, Batch:  2144] loss: 0.017\n",
      "[Epoch: 1, Batch:  2176] loss: 0.015\n",
      "[Epoch: 1, Batch:  2208] loss: 0.009\n",
      "[Epoch: 1, Batch:  2240] loss: 0.012\n",
      "[Epoch: 1, Batch:  2272] loss: 0.013\n",
      "[Epoch: 1, Batch:  2304] loss: 0.012\n",
      "[Epoch: 1, Batch:  2336] loss: 0.013\n",
      "[Epoch: 1, Batch:  2368] loss: 0.020\n",
      "[Epoch: 1, Batch:  2400] loss: 0.012\n",
      "[Epoch: 1, Batch:  2432] loss: 0.015\n",
      "[Epoch: 1, Batch:  2464] loss: 0.013\n",
      "[Epoch: 1, Batch:  2496] loss: 0.013\n",
      "[Epoch: 1, Batch:  2528] loss: 0.021\n",
      "[Epoch: 1, Batch:  2560] loss: 0.017\n",
      "[Epoch: 1, Batch:  2592] loss: 0.017\n",
      "[Epoch: 1, Batch:  2624] loss: 0.019\n",
      "[Epoch: 1, Batch:  2656] loss: 0.010\n",
      "[Epoch: 1, Batch:  2688] loss: 0.012\n",
      "[Epoch: 1, Batch:  2720] loss: 0.019\n",
      "[Epoch: 1, Batch:  2752] loss: 0.015\n",
      "[Epoch: 1, Batch:  2784] loss: 0.013\n",
      "[Epoch: 1, Batch:  2816] loss: 0.013\n",
      "[Epoch: 1, Batch:  2848] loss: 0.017\n",
      "[Epoch: 1, Batch:  2880] loss: 0.016\n",
      "[Epoch: 1, Batch:  2912] loss: 0.021\n",
      "[Epoch: 1, Batch:  2944] loss: 0.016\n",
      "[Epoch: 1, Batch:  2976] loss: 0.012\n",
      "[Epoch: 1, Batch:  3008] loss: 0.016\n",
      "[Epoch: 1, Batch:  3040] loss: 0.014\n",
      "[Epoch: 1, Batch:  3072] loss: 0.010\n",
      "[Epoch: 1, Batch:  3104] loss: 0.018\n",
      "[Epoch: 1, Batch:  3136] loss: 0.017\n",
      "[Epoch: 1, Batch:  3168] loss: 0.019\n",
      "[Epoch: 1, Batch:  3200] loss: 0.017\n",
      "[Epoch: 1, Batch:  3232] loss: 0.010\n",
      "[Epoch: 1, Batch:  3264] loss: 0.013\n",
      "[Epoch: 1, Batch:  3296] loss: 0.009\n",
      "[Epoch: 1, Batch:  3328] loss: 0.017\n",
      "[Epoch: 1, Batch:  3360] loss: 0.010\n",
      "[Epoch: 1, Batch:  3392] loss: 0.011\n",
      "[Epoch: 1, Batch:  3424] loss: 0.011\n",
      "[Epoch: 1, Batch:  3456] loss: 0.010\n",
      "[Epoch: 1, Batch:  3488] loss: 0.024\n",
      "[Epoch: 1, Batch:  3520] loss: 0.014\n",
      "[Epoch: 1, Batch:  3552] loss: 0.014\n",
      "[Epoch: 1, Batch:  3584] loss: 0.019\n",
      "[Epoch: 1, Batch:  3616] loss: 0.013\n",
      "[Epoch: 1, Batch:  3648] loss: 0.014\n",
      "[Epoch: 1, Batch:  3680] loss: 0.014\n",
      "[Epoch: 1, Batch:  3712] loss: 0.015\n",
      "[Epoch: 1, Batch:  3744] loss: 0.019\n",
      "[Epoch: 1, Batch:  3776] loss: 0.021\n",
      "[Epoch: 1, Batch:  3808] loss: 0.013\n",
      "[Epoch: 1, Batch:  3840] loss: 0.013\n",
      "[Epoch: 1, Batch:  3872] loss: 0.010\n",
      "[Epoch: 1, Batch:  3904] loss: 0.012\n",
      "[Epoch: 1, Batch:  3936] loss: 0.018\n",
      "[Epoch: 1, Batch:  3968] loss: 0.015\n",
      "[Epoch: 1, Batch:  4000] loss: 0.020\n",
      "[Epoch: 1, Batch:  4032] loss: 0.019\n",
      "[Epoch: 1, Batch:  4064] loss: 0.020\n",
      "[Epoch: 1, Batch:  4096] loss: 0.014\n",
      "[Epoch: 1, Batch:  4128] loss: 0.016\n",
      "[Epoch: 1, Batch:  4160] loss: 0.012\n",
      "[Epoch: 1, Batch:  4192] loss: 0.011\n",
      "[Epoch: 1, Batch:  4224] loss: 0.015\n",
      "[Epoch: 1, Batch:  4256] loss: 0.016\n",
      "[Epoch: 1, Batch:  4288] loss: 0.014\n",
      "[Epoch: 1, Batch:  4320] loss: 0.020\n",
      "[Epoch: 1, Batch:  4352] loss: 0.014\n",
      "[Epoch: 1, Batch:  4384] loss: 0.021\n",
      "[Epoch: 1, Batch:  4416] loss: 0.013\n",
      "[Epoch: 1, Batch:  4448] loss: 0.012\n",
      "[Epoch: 1, Batch:  4480] loss: 0.010\n",
      "[Epoch: 1, Batch:  4512] loss: 0.014\n",
      "[Epoch: 1, Batch:  4544] loss: 0.012\n",
      "[Epoch: 1, Batch:  4576] loss: 0.016\n",
      "[Epoch: 1, Batch:  4608] loss: 0.022\n",
      "[Epoch: 1, Batch:  4640] loss: 0.015\n",
      "[Epoch: 1, Batch:  4672] loss: 0.016\n",
      "[Epoch: 1, Batch:  4704] loss: 0.015\n",
      "[Epoch: 1, Batch:  4736] loss: 0.018\n",
      "[Epoch: 1, Batch:  4768] loss: 0.014\n",
      "[Epoch: 1, Batch:  4800] loss: 0.014\n",
      "[Epoch: 1, Batch:  4832] loss: 0.014\n",
      "[Epoch: 1, Batch:  4864] loss: 0.014\n",
      "[Epoch: 1, Batch:  4896] loss: 0.021\n",
      "[Epoch: 1, Batch:  4928] loss: 0.015\n",
      "[Epoch: 1, Batch:  4960] loss: 0.011\n",
      "[Epoch: 1, Batch:  4992] loss: 0.015\n",
      "[Epoch: 1, Batch:  5024] loss: 0.020\n",
      "[Epoch: 1, Batch:  5056] loss: 0.012\n",
      "[Epoch: 1, Batch:  5088] loss: 0.013\n",
      "[Epoch: 1, Batch:  5120] loss: 0.017\n",
      "[Epoch: 1, Batch:  5152] loss: 0.010\n",
      "[Epoch: 1, Batch:  5184] loss: 0.019\n",
      "[Epoch: 1, Batch:  5216] loss: 0.013\n",
      "[Epoch: 1, Batch:  5248] loss: 0.015\n",
      "[Epoch: 1, Batch:  5280] loss: 0.015\n",
      "[Epoch: 1, Batch:  5312] loss: 0.016\n",
      "[Epoch: 1, Batch:  5344] loss: 0.014\n",
      "[Epoch: 1, Batch:  5376] loss: 0.014\n",
      "[Epoch: 1, Batch:  5408] loss: 0.025\n",
      "[Epoch: 1, Batch:  5440] loss: 0.015\n",
      "[Epoch: 1, Batch:  5472] loss: 0.011\n",
      "[Epoch: 1, Batch:  5504] loss: 0.016\n",
      "[Epoch: 1, Batch:  5536] loss: 0.014\n",
      "[Epoch: 1, Batch:  5568] loss: 0.014\n",
      "[Epoch: 1, Batch:  5600] loss: 0.014\n",
      "[Epoch: 1, Batch:  5632] loss: 0.016\n",
      "[Epoch: 1, Batch:  5664] loss: 0.015\n",
      "[Epoch: 1, Batch:  5696] loss: 0.012\n",
      "[Epoch: 1, Batch:  5728] loss: 0.014\n",
      "[Epoch: 1, Batch:  5760] loss: 0.018\n",
      "[Epoch: 1, Batch:  5792] loss: 0.009\n",
      "[Epoch: 1, Batch:  5824] loss: 0.017\n",
      "[Epoch: 1, Batch:  5856] loss: 0.019\n",
      "[Epoch: 1, Batch:  5888] loss: 0.015\n",
      "[Epoch: 1, Batch:  5920] loss: 0.015\n",
      "[Epoch: 1, Batch:  5952] loss: 0.021\n",
      "[Epoch: 1, Batch:  5984] loss: 0.016\n",
      "[Epoch: 1, Batch:  6016] loss: 0.016\n",
      "[Epoch: 1, Batch:  6048] loss: 0.012\n",
      "Accuracy of the network on the test images: 97 %\n",
      "F1 Score of the network on the test images: 0.884537\n",
      "[Epoch: 2, Batch:    32] loss: 0.014\n",
      "[Epoch: 2, Batch:    64] loss: 0.013\n",
      "[Epoch: 2, Batch:    96] loss: 0.015\n",
      "[Epoch: 2, Batch:   128] loss: 0.021\n",
      "[Epoch: 2, Batch:   160] loss: 0.015\n",
      "[Epoch: 2, Batch:   192] loss: 0.013\n",
      "[Epoch: 2, Batch:   224] loss: 0.011\n",
      "[Epoch: 2, Batch:   256] loss: 0.014\n",
      "[Epoch: 2, Batch:   288] loss: 0.009\n",
      "[Epoch: 2, Batch:   320] loss: 0.011\n",
      "[Epoch: 2, Batch:   352] loss: 0.012\n",
      "[Epoch: 2, Batch:   384] loss: 0.015\n",
      "[Epoch: 2, Batch:   416] loss: 0.019\n",
      "[Epoch: 2, Batch:   448] loss: 0.013\n",
      "[Epoch: 2, Batch:   480] loss: 0.018\n",
      "[Epoch: 2, Batch:   512] loss: 0.013\n",
      "[Epoch: 2, Batch:   544] loss: 0.018\n",
      "[Epoch: 2, Batch:   576] loss: 0.016\n",
      "[Epoch: 2, Batch:   608] loss: 0.017\n",
      "[Epoch: 2, Batch:   640] loss: 0.016\n",
      "[Epoch: 2, Batch:   672] loss: 0.012\n",
      "[Epoch: 2, Batch:   704] loss: 0.014\n",
      "[Epoch: 2, Batch:   736] loss: 0.019\n",
      "[Epoch: 2, Batch:   768] loss: 0.019\n",
      "[Epoch: 2, Batch:   800] loss: 0.014\n",
      "[Epoch: 2, Batch:   832] loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2, Batch:   864] loss: 0.018\n",
      "[Epoch: 2, Batch:   896] loss: 0.019\n",
      "[Epoch: 2, Batch:   928] loss: 0.012\n",
      "[Epoch: 2, Batch:   960] loss: 0.012\n",
      "[Epoch: 2, Batch:   992] loss: 0.019\n",
      "[Epoch: 2, Batch:  1024] loss: 0.015\n",
      "[Epoch: 2, Batch:  1056] loss: 0.015\n",
      "[Epoch: 2, Batch:  1088] loss: 0.013\n",
      "[Epoch: 2, Batch:  1120] loss: 0.011\n",
      "[Epoch: 2, Batch:  1152] loss: 0.015\n",
      "[Epoch: 2, Batch:  1184] loss: 0.011\n",
      "[Epoch: 2, Batch:  1216] loss: 0.013\n",
      "[Epoch: 2, Batch:  1248] loss: 0.012\n",
      "[Epoch: 2, Batch:  1280] loss: 0.025\n",
      "[Epoch: 2, Batch:  1312] loss: 0.015\n",
      "[Epoch: 2, Batch:  1344] loss: 0.015\n",
      "[Epoch: 2, Batch:  1376] loss: 0.012\n",
      "[Epoch: 2, Batch:  1408] loss: 0.013\n",
      "[Epoch: 2, Batch:  1440] loss: 0.011\n",
      "[Epoch: 2, Batch:  1472] loss: 0.020\n",
      "[Epoch: 2, Batch:  1504] loss: 0.010\n",
      "[Epoch: 2, Batch:  1536] loss: 0.018\n",
      "[Epoch: 2, Batch:  1568] loss: 0.016\n"
     ]
    }
   ],
   "source": [
    "train_losses_2, val_losses_2, F1_scores_2, accuracies_2 = train(pollen_network, trainloader, ep, criterion, optimizer, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_pollen_data(dir):\n",
    "#     np_pollen_data = []     # single date will be [img,label]\n",
    "#     for folder in next(os.walk(dir))[1]:\n",
    "#         if folder == 'p':\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             label = 0\n",
    "#         parent_path = os.path.join(dir, folder)\n",
    "#         for file in os.listdir(parent_path):\n",
    "#             if '.png' in file:\n",
    "#                 try:\n",
    "#                     path = os.path.join(parent_path, file)\n",
    "#                     img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "#                     np_pollen_data.append([np.array(img), label])\n",
    "#                 except Exception as e:\n",
    "#                     print(folder, file, str(e))\n",
    "\n",
    "#     data = np.random.shuffle(np_pollen_data)\n",
    "#     print(\"Data created.\")\n",
    "#     return np_pollen_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_test_val_sets(data, ratio=0.8):\n",
    "#     \"\"\"\n",
    "#     Splits the data into a training and a validation data set.\n",
    "    \n",
    "#     Parameters:\n",
    "#         data ([[obj, obj]]): A list of lists, which contain a sample and the correponding label.\n",
    "#         ratio (float): The ratio between the size of the validation and the training data set.\n",
    "        \n",
    "#     Returns:\n",
    "#         train_x ([obj]): The samples of the training data set.\n",
    "#         train_y ([obj]): The corresponding labels of the training data set.\n",
    "#         valid_x ([obj]): The samples of the validation data set.\n",
    "#         valid_y ([obj]): The corresponding labels of the validation data set.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     images = []\n",
    "#     labels = []\n",
    "\n",
    "#     for i in range(len(data)):\n",
    "#         images.append(data[i][0])\n",
    "#         labels.append(data[i][1])\n",
    "    \n",
    "#     train_x = images[:int(len(images)*ratio)]\n",
    "#     train_y = labels[:int(len(images)*ratio)]\n",
    "#     valid_x = images[int(len(images)*ratio):]\n",
    "#     valid_y = labels[int(len(images)*ratio):]\n",
    "    \n",
    "#     print(\"Sets created\")\n",
    "#     return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Data\n",
    "# cur_dir = os.getcwd()\n",
    "# pollen_path = os.path.join(cur_dir, 'Datasets/PollenData64')\n",
    "# pollendata = load_pollen_data(pollen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into sets\n",
    "# train_x, train_y, valid_x, valid_y = create_test_val_sets(pollendata, 0.9)\n",
    "\n",
    "# pollendata = []\n",
    "\n",
    "# # Our neural network expects a dataloader\n",
    "# trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(train_x),torch.Tensor(train_y)),batch_size=32)\n",
    "# validloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(valid_x),torch.Tensor(valid_y)),batch_size=1)\n",
    "\n",
    "# # Save dataloader for later use\n",
    "# #torch.save(trainloader, 'trainloader.pth')\n",
    "# #torch.save(validloader, 'validloader.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup wether gpu or cpu should be used for computations\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Create a new instance of the FCNN class. This will be our network.      \n",
    "# pollen_network = FCNN().to(device)\n",
    "\n",
    "# # Choose optimizer, criterion, number of epochs and threshold for the network to accept or dismiss a computated input\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(pollen_network.parameters(), lr=0.001, momentum=0.9)\n",
    "# ep = 10\n",
    "# threshold = 0.8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

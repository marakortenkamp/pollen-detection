{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a class for fully convolutional neural networks.\n",
    "    \n",
    "    It is a subclass of the Module class from torch.nn.\n",
    "    See the torch.nn documentation for more information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor for FCNN class. The internal states of the network are initialized. \n",
    "        \"\"\"\n",
    "        \n",
    "        super(FCNN, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=30, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=30, out_channels=60, kernel_size=3, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=60, out_channels=60, kernel_size=3, stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=60, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=120, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=120, out_channels=1, kernel_size=1, stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Defines the computation performed at every call.\n",
    "        \n",
    "        Parameters:\n",
    "            data (torch.Tensor): The input that is evaluated by the network. \n",
    "                The network expects the input to be of 4 dimensions.\n",
    "            \n",
    "        Returns:\n",
    "            x (torch.Tensor): The output of the network after evaluating it on the given input.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.relu(self.conv0(data))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2_drop(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_drop(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = torch.sigmoid(self.conv6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which network to load\n",
    "cur_dir = os.getcwd()\n",
    "path_to_network = os.path.join(cur_dir, 'pollennet.pt')\n",
    "\n",
    "# initialise blank network\n",
    "pollen_network = FCNN()\n",
    "# update with saved weights\n",
    "\n",
    "pollen_network.load_state_dict(torch.load(path_to_network, map_location={'cuda:0': 'cpu'}))\n",
    "pollen_network.eval()\n",
    "# define criterion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(pollen_network.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # load validloader and losses:\n",
    "# TODO\n",
    "# printloader should load validloader with torch.load() somehow\n",
    "# losses with pickle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show loaded weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "\n",
      "Weights of the first layer:\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0986, -0.0424],\n",
      "          [ 0.2190,  0.2284]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1057, -0.0636],\n",
      "          [ 0.3646,  0.2155]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0266, -0.2808],\n",
      "          [ 0.1276, -0.1018]]],\n",
      "\n",
      "\n",
      "        [[[-0.2647, -0.0161],\n",
      "          [-0.2710, -0.4592]]],\n",
      "\n",
      "\n",
      "        [[[-0.4651, -0.1534],\n",
      "          [ 0.3088,  0.1992]]],\n",
      "\n",
      "\n",
      "        [[[-0.2286, -0.1250],\n",
      "          [-0.3302, -0.3245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2022,  0.4456],\n",
      "          [ 0.3600,  0.4520]]],\n",
      "\n",
      "\n",
      "        [[[-0.0997, -0.3818],\n",
      "          [ 0.1190, -0.1973]]],\n",
      "\n",
      "\n",
      "        [[[-0.3771,  0.4947],\n",
      "          [ 0.0497,  0.3222]]],\n",
      "\n",
      "\n",
      "        [[[-0.2047, -0.1365],\n",
      "          [-0.4003, -0.0844]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2733,  0.2067],\n",
      "          [-0.2521,  0.0673]]],\n",
      "\n",
      "\n",
      "        [[[-0.0484, -0.4543],\n",
      "          [ 0.3958,  0.0291]]],\n",
      "\n",
      "\n",
      "        [[[-0.4005,  0.4118],\n",
      "          [-0.1296, -0.3436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2999,  0.0191],\n",
      "          [ 0.2623, -0.3160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0740,  0.1266],\n",
      "          [-0.3545, -0.0861]]],\n",
      "\n",
      "\n",
      "        [[[-0.4976,  0.4586],\n",
      "          [-0.0199, -0.0623]]],\n",
      "\n",
      "\n",
      "        [[[-0.0461,  0.2932],\n",
      "          [ 0.4652,  0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.1130,  0.2005],\n",
      "          [ 0.3821, -0.0136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4990, -0.3827],\n",
      "          [-0.2590, -0.3949]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3444,  0.4666],\n",
      "          [-0.3274, -0.2092]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5148, -0.0305],\n",
      "          [-0.0264, -0.2471]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3687, -0.3551],\n",
      "          [-0.3519,  0.4242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0088, -0.1115],\n",
      "          [ 0.3893, -0.0150]]],\n",
      "\n",
      "\n",
      "        [[[-0.3831, -0.1559],\n",
      "          [-0.0911,  0.1001]]],\n",
      "\n",
      "\n",
      "        [[[-0.2863, -0.4669],\n",
      "          [ 0.2204,  0.3107]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2630, -0.4409],\n",
      "          [-0.3463, -0.0727]]],\n",
      "\n",
      "\n",
      "        [[[-0.0658, -0.2485],\n",
      "          [-0.0804,  0.4862]]],\n",
      "\n",
      "\n",
      "        [[[-0.4048,  0.4827],\n",
      "          [ 0.4388,  0.2120]]],\n",
      "\n",
      "\n",
      "        [[[-0.2306,  0.4257],\n",
      "          [-0.1432, -0.2910]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4268, -0.2337],\n",
      "          [-0.0040, -0.4699]]]], requires_grad=True)\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Model's state_dict:\n",
      "conv0.weight \t torch.Size([30, 1, 2, 2])\n",
      "conv0.bias \t torch.Size([30])\n",
      "conv1.weight \t torch.Size([30, 30, 5, 5])\n",
      "conv1.bias \t torch.Size([30])\n",
      "conv2.weight \t torch.Size([60, 30, 3, 3])\n",
      "conv2.bias \t torch.Size([60])\n",
      "conv3.weight \t torch.Size([60, 60, 3, 3])\n",
      "conv3.bias \t torch.Size([60])\n",
      "conv4.weight \t torch.Size([120, 60, 3, 3])\n",
      "conv4.bias \t torch.Size([120])\n",
      "conv5.weight \t torch.Size([120, 120, 3, 3])\n",
      "conv5.bias \t torch.Size([120])\n",
      "conv6.weight \t torch.Size([1, 120, 1, 1])\n",
      "conv6.bias \t torch.Size([1])\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139737287838208, 139737287837568, 139737287839616, 139737287836672, 139737287838656, 139737287838336, 139737287836992, 139737287839488, 139737287839552, 139737287836864, 139737287837248, 139737287839424, 139737287839296, 139737287836800]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------\\n\")\n",
    "print(\"Weights of the first layer:\")\n",
    "print(pollen_network.conv0.weight)\n",
    "\n",
    "print(\"\\n-----------------------------\\n\")\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in pollen_network.state_dict():\n",
    "    print(param_tensor, \"\\t\", pollen_network.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"\\n-----------------------------\\n\")\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show how data is transformed in size while going through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pollen_network, (1,64,64))\n",
    "print(\"-----------------------------\")\n",
    "summary(pollen_network, (1,4000,3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-07d30b1a06af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF1_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Train Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F1-Score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.plot(F1_scores)\n",
    "plt.plot(accuracies)\n",
    "plt.legend([\"Train Loss\", \"Validation Loss\", \"F1-Score\", \"Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some wrong classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was used to find the weaknesses of the network.\n",
    "\n",
    "def print_false_positive(network, testloader):\n",
    "    \"\"\"\n",
    "    Evaluates the network and prints the false positives samples. \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counter = 0\n",
    "    # We do not need any gradiants here, since we do not train the network.\n",
    "    # We are only interested in the predictions of the network on the testdata. \n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(testloader):\n",
    "#         for i, (inputs, labels) in enumerate(testloader):\n",
    "            inputs = sample['image']\n",
    "            labels = sample['label']\n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)).view(-1)\n",
    "            predicted = (outputs >= threshold) # Predicted is a tensor of booleans \n",
    "            predicted = predicted.view(predicted.size(0))\n",
    "            labels = labels != 0\n",
    "            if (predicted and not labels):\n",
    "                title = 'Label: False, Predicted: True'\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.imshow(np.array(inputs[0]), cmap='gray')\n",
    "                ax.set_title(title)\n",
    "                plt.show()\n",
    "                counter += 1\n",
    "                if counter == 20:\n",
    "                    break\n",
    "    return counter\n",
    "\n",
    "def print_false_negative(network, testloader):\n",
    "    # We do not need any gradiants here, since we do not train the network.\n",
    "    # We are only interested in the predictions of the network on the testdata. \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(testloader):\n",
    "#         for i, (inputs, labels) in enumerate(testloader):\n",
    "\n",
    "            inputs = sample['image']\n",
    "            labels = sample['label']\n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)).view(-1)\n",
    "            predicted = (outputs >= threshold) # Predicted is a tensor of booleans \n",
    "            predicted = predicted.view(predicted.size(0))\n",
    "            labels = labels != 0\n",
    "            if (not predicted and labels):\n",
    "                title = 'Label: True, Predicted: False'\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.imshow(np.array(inputs[0]), cmap='gray')\n",
    "                ax.set_title(title)\n",
    "                plt.show()\n",
    "                counter += 1\n",
    "                if counter == 20:\n",
    "                    break\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'printloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-31360efd6b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_false_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpollen_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint_false_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpollen_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'printloader' is not defined"
     ]
    }
   ],
   "source": [
    "print_false_positive(pollen_network, printloader)\n",
    "print(\"-----------------------------\")\n",
    "print_false_negative(pollen_network, printloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(dir):\n",
    "    \"\"\"returns samples in given directory\"\"\"\n",
    "\n",
    "    # samples will be a list of tuples, each tuple contains a path and a list of coords of a single image\n",
    "    samples = []\n",
    "    for root, folders, files in os.walk(dir):\n",
    "        for folder in folders:\n",
    "            if folder == 'img':\n",
    "                for img_root, img_folder, img_files in os.walk(os.path.join(root, folder)):\n",
    "                    for img_file in img_files:\n",
    "                        # go find its related annotation file:\n",
    "                        found_ann = False\n",
    "                        for ann_root, ann_folder, ann_files in os.walk(os.path.join(root, 'ann')):\n",
    "                            if found_ann:\n",
    "                                break\n",
    "                            for ann_file in ann_files:\n",
    "                                if img_file in ann_file:\n",
    "                                    # found a pair!\n",
    "                                    cur_coords = []\n",
    "                                    with open(os.path.join(ann_root, ann_file)) as ann_json:\n",
    "                                        ann_data = json.load(ann_json)\n",
    "                                    cur_len = len(ann_data['objects'])\n",
    "                                    if cur_len:\n",
    "                                        for obj in ann_data['objects']:\n",
    "                                            cur_coords.append(obj['points']['exterior'][0])\n",
    "                                        img_path = os.path.join(img_root, img_file)\n",
    "                                        np_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                                        samples.append((np.array(np_img), cur_coords))\n",
    "                                    # to prevent unnecessary looping:\n",
    "                                    found_ann = True\n",
    "                                    break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat(network, samples):\n",
    "    \"\"\"\n",
    "    Feeds images of any size into the network and returns the belonging heatmaps. \n",
    "    \n",
    "    Parameters:\n",
    "        network (FCNN): A fully convolutional neural network, that is used to compute a heatmap.\n",
    "        testloader (torch.utils.data.DataLoader): Dataloader with batch size 1 that contains the\n",
    "            images you want to compute the heatmaps of\n",
    "        \n",
    "    Returns:\n",
    "        heatmaps ([np.array]): A list which contains a heatmap that is a 2D array for every input image.\n",
    "    \"\"\"\n",
    "    \n",
    "    heatmaps = []\n",
    "    print('Creating heatmaps...')\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for fs_image, fs_coords in samples:\n",
    "            t_image = torch.Tensor(fs_image)[None, ...]\n",
    "            # outputs = network(torch.transpose(inputs[...,None],1,3))\n",
    "            heatmap = network(torch.transpose(t_image[...,None],1,3))\n",
    "            heatmaps.append((np.array(torch.transpose(heatmap[0,0,:,:],0,1)),fs_coords))\n",
    "            \n",
    "    print('Heatmaps created.')\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find local maxima with max-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(heatmaps, local_size = 8):\n",
    "    heatmaps_sup = []\n",
    "    pooling = nn.MaxPool2d((local_size * 2 - 1), stride = 1, padding = local_size - 1)\n",
    "    for heatmap in heatmaps:\n",
    "        max_filter = pooling(torch.tensor(heatmap)[None,...])\n",
    "        max_filter = np.array(max_filter)\n",
    "        heatmap = ((heatmap == max_filter) * (heatmap >= 0.8)).astype(int)\n",
    "        heatmaps_sup.append(heatmap[0,:,:])\n",
    "        \n",
    "    return heatmaps_sup\n",
    "\n",
    "def non_max_suppression_single(heatmap, local_size = 8):\n",
    "    pooling = nn.MaxPool2d((local_size * 2 - 1), stride = 1, padding = local_size - 1)\n",
    "    max_filter = pooling(torch.tensor(heatmap)[None,...])\n",
    "    max_filter = np.array(max_filter)\n",
    "    heatmap = ((heatmap == max_filter) * (heatmap >= 0.8)).astype(int)\n",
    "    heatmap_sup = heatmap[0,:,:]\n",
    "        \n",
    "    return heatmap_sup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract coordiantes of predicted pollen in heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pollen_coordinates(heatmap):\n",
    "    coordinate_list = []\n",
    "    h_coordinates = np.argwhere(heatmap == 1)\n",
    "    for i in range(h_coordinates.shape[0]):\n",
    "        coordinate_list.append((h_coordinates[i,0] * 2 * 2 * 2 + 28, h_coordinates[i,1] * 2 * 2 * 2 + 28))\n",
    "    return coordinate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Image with actual Pollen and predicted locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_plotter(img, network_guess, actual_points):\n",
    "\n",
    "    np_img = np.array(Image.open(img), dtype=np.uint8)\n",
    "    main_fig,ax = plt.subplots(1)\n",
    "    ax.imshow(np_img)\n",
    "\n",
    "    for coord in actual_points:\n",
    "        crcl = patches.Circle((coord[0],coord[1]),35,linewidth=4,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(crcl)\n",
    "\n",
    "    for coord in network_guess:\n",
    "        crcl = patches.Circle((coord[0],coord[1]),20,linewidth=2,edgecolor='b',facecolor='none')\n",
    "        ax.add_patch(crcl)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images\n",
    "cur_dir = os.getcwd()\n",
    "full_size_path = os.path.join(curd_dir, 'Fullsize')\n",
    "full_size_images = get_samples(full_size_path)\n",
    "\n",
    "# Create heatmap of images\n",
    "heatmaps = heat(network,full_size_images)\n",
    "\n",
    "# Find local maxima on heatmaps\n",
    "non_max_heatmaps = [(non_max_suppression_single(heatmap),coords) for heatmap, coords in heatmaps]\n",
    "\n",
    "# TODO\n",
    "# plot images with predicted and real pollen marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

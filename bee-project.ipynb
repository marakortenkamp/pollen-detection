{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Fully Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=30, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=30, out_channels=60, kernel_size=3, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=60, out_channels=60, kernel_size=3, stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=60, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=120, out_channels=120, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=120, out_channels=1, kernel_size=3, stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data))\n",
    "        x = F.relu(self.conv2_drop(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_drop(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x\n",
    "        \n",
    "network = FCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data created.\n"
     ]
    }
   ],
   "source": [
    "POLLEN_DATA_CREATED = False\n",
    "cur_dir = os.getcwd()\n",
    "pollen_files = cur_dir + '/Data/PollenData/'\n",
    "np_pollen_data = []     # single date will be [img,label]\n",
    "\n",
    "\n",
    "if not POLLEN_DATA_CREATED:\n",
    "    for folder in next(os.walk(pollen_files))[1]:\n",
    "        if folder == 'Real':\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        parent_path = os.path.join(pollen_files, folder)\n",
    "        for file in os.listdir(parent_path):\n",
    "            if '.png' in file:\n",
    "                try:\n",
    "                    path = os.path.join(parent_path, file)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    np_pollen_data.append([np.array(img), label])\n",
    "                except Exception as e:\n",
    "                    print(folder, file, str(e))\n",
    "\n",
    "    np.random.shuffle(np_pollen_data)\n",
    "    print(\"Data created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246\n"
     ]
    }
   ],
   "source": [
    "# seperate the images and the labels into two lists:\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(np_pollen_data)):\n",
    "    images.append(np_pollen_data[i][0])\n",
    "    labels.append(np_pollen_data[i][1])\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation set:\n",
    "\n",
    "train_x = images[:int(len(images)*0.8)]\n",
    "train_y = labels[:int(len(images)*0.8)]\n",
    "valid_x = images[int(len(images)*0.8):]\n",
    "valid_y = labels[int(len(images)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(images[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(train_x),torch.Tensor(train_y)),batch_size=10)\n",
    "validloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(valid_x),torch.Tensor(valid_y)),batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "and splitting the dataset into train and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform to tensor\n",
    "pollen_data = [[torch.from_numpy(i[0]).view(-1,32,32)/255.0,i[1]] for i in np_pollen_data]\n",
    "\n",
    "#create datasets\n",
    "data_amount = len(pollen_data)\n",
    "train_size = int(data_amount*0.8)\n",
    "val_size = int(data_amount*0.1)\n",
    "\n",
    "pollen_training_set = pollen_data[:train_size]\n",
    "pollen_validation_set = pollen_data[train_size:val_size]\n",
    "pollen_testing_set = pollen_data[val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have a look at the performance of the untrained model on our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 51 %\n"
     ]
    }
   ],
   "source": [
    "def validate(network, testloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    # We do not need any gradiants here, since we do not train the network.\n",
    "    # We are only interested in the predictions of the network on the testdata. \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)) \n",
    "            #print(labels.size(0))\n",
    "            predicted = (outputs >= 0.9) # Predicted is a tensor of booleans \n",
    "            total += labels.size(0)\n",
    "            predicted = predicted.view(predicted.size(0)) \n",
    "            #print(labels.size())\n",
    "            #print((predicted == labels).sum().item())\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "    \n",
    "validate(network, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 10;\n",
    "\n",
    "#Which optimizer and criterion should we choose? Perform best?\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    32] loss: 0.435\n",
      "[1,    64] loss: 0.398\n",
      "[1,    96] loss: 0.427\n",
      "[1,   128] loss: 0.496\n",
      "[1,   160] loss: 0.413\n",
      "[1,   192] loss: 0.441\n",
      "[1,   224] loss: 0.508\n",
      "[1,   256] loss: 0.463\n",
      "[2,    32] loss: 0.478\n",
      "[2,    64] loss: 0.464\n",
      "[2,    96] loss: 0.468\n",
      "[2,   128] loss: 0.515\n",
      "[2,   160] loss: 0.489\n",
      "[2,   192] loss: 0.502\n",
      "[2,   224] loss: 0.404\n",
      "[2,   256] loss: 0.274\n",
      "[3,    32] loss: 0.258\n",
      "[3,    64] loss: 0.262\n",
      "[3,    96] loss: 0.238\n",
      "[3,   128] loss: 0.342\n",
      "[3,   160] loss: 0.176\n",
      "[3,   192] loss: 0.302\n",
      "[3,   224] loss: 0.321\n",
      "[3,   256] loss: 0.258\n",
      "[4,    32] loss: 0.164\n",
      "[4,    64] loss: 0.148\n",
      "[4,    96] loss: 0.101\n",
      "[4,   128] loss: 0.166\n",
      "[4,   160] loss: 0.224\n",
      "[4,   192] loss: 0.202\n",
      "[4,   224] loss: 0.237\n",
      "[4,   256] loss: 0.204\n",
      "[5,    32] loss: 0.138\n",
      "[5,    64] loss: 0.179\n",
      "[5,    96] loss: 0.120\n",
      "[5,   128] loss: 0.192\n",
      "[5,   160] loss: 0.144\n",
      "[5,   192] loss: 0.125\n",
      "[5,   224] loss: 0.130\n",
      "[5,   256] loss: 0.115\n",
      "[6,    32] loss: 0.136\n",
      "[6,    64] loss: 0.121\n",
      "[6,    96] loss: 0.123\n",
      "[6,   128] loss: 0.216\n",
      "[6,   160] loss: 0.183\n",
      "[6,   192] loss: 0.169\n",
      "[6,   224] loss: 0.121\n",
      "[6,   256] loss: 0.144\n",
      "[7,    32] loss: 0.210\n",
      "[7,    64] loss: 0.307\n",
      "[7,    96] loss: 0.390\n",
      "[7,   128] loss: 0.461\n",
      "[7,   160] loss: 0.481\n",
      "[7,   192] loss: 0.444\n",
      "[7,   224] loss: 0.506\n",
      "[7,   256] loss: 0.525\n",
      "[8,    32] loss: 0.528\n",
      "[8,    64] loss: 0.528\n",
      "[8,    96] loss: 0.525\n",
      "[8,   128] loss: 0.466\n",
      "[8,   160] loss: 0.478\n",
      "[8,   192] loss: 0.444\n",
      "[8,   224] loss: 0.504\n",
      "[8,   256] loss: 0.519\n",
      "[9,    32] loss: 0.528\n",
      "[9,    64] loss: 0.522\n",
      "[9,    96] loss: 0.516\n",
      "[9,   128] loss: 0.453\n",
      "[9,   160] loss: 0.389\n",
      "[9,   192] loss: 0.375\n",
      "[9,   224] loss: 0.250\n",
      "[9,   256] loss: 0.335\n",
      "[10,    32] loss: 0.287\n",
      "[10,    64] loss: 0.252\n",
      "[10,    96] loss: 0.160\n",
      "[10,   128] loss: 0.189\n",
      "[10,   160] loss: 0.140\n",
      "[10,   192] loss: 0.160\n",
      "[10,   224] loss: 0.165\n",
      "[10,   256] loss: 0.158\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# from pytorch blitz tutorial\n",
    "\n",
    "def train(network, trainloader, ep, criterion, optimizer, print_interval):\n",
    "    for epoch in range(ep):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, (inputs, lables) in enumerate(trainloader):\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(lables.shape)\n",
    "            \n",
    "            outputs = network(torch.transpose(inputs[...,None],1,3)).view(-1)\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs, lables)\n",
    "            loss.backward() #propagate the error back through the network\n",
    "            optimizer.step() #adjust the weights of the network depending on the propagated error\n",
    "    \n",
    "            #that's it.\n",
    "    \n",
    "            #Some statistics:\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            if i % print_interval == print_interval - 1:    # print every x mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / print_interval))\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    "train(network, trainloader, ep, criterion, optimizer, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "The performance on the validation data after training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 88 %\n"
     ]
    }
   ],
   "source": [
    "validate(network, validloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
